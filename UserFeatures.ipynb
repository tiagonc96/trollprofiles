{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopword_nr(sentence):\n",
    "    \n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    count=0\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    for stopword in stopwords:\n",
    "        for word in word_tokens:\n",
    "            if stopword==word:\n",
    "                count+=1\n",
    "       \n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_of_comment(jsonLine):\n",
    "     \n",
    "    dateStr=str(jsonLine)\n",
    "       \n",
    "    fullDateArray=dateStr.split()\n",
    "    time=fullDateArray[1].split('+')\n",
    "    \n",
    "    return time[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nr_of_hashtags(jsonLine):\n",
    "    return len(jsonLine['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nr_of_mentions(jsonLine):\n",
    "    try:\n",
    "        mentions=len(jsonLine['mentions'])\n",
    "        return mentions\n",
    "    except:\n",
    "        mentions=len(jsonLine['user_mentions'])\n",
    "        return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nr_of_urls(jsonLine):\n",
    "    return len(jsonLine['urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nr_of_emoticons(jsonLine):\n",
    "    try:\n",
    "        emoticons= len(jsonLine['emoticons'])\n",
    "        return emoticons\n",
    "    except:\n",
    "        emoticons=len(jsonLine['symbols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swear_count(jsonLine):\n",
    "    swearCount=0\n",
    "    swears=['broch','cabrões','cabr','cagalhão','caralh','cona','corn','enrabar','cuzinho','esporra','fod','mamadas','panasca','peid','piça','picha','pila','tomates','puta','merd','caralho','crl','fds','fdç','paneleir']\n",
    "    for swear in swears:\n",
    "        if swear.lower() in jsonLine.lower():\n",
    "            swearCount+=1\n",
    "            \n",
    "    return swearCount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_favorites_count(jsonLine):\n",
    "    return jsonLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_of_tweet(jsonLine):\n",
    "    dateStr=str(jsonLine)\n",
    "       \n",
    "    fullDateArray=dateStr.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_count(jsonLine):\n",
    "    sentence=jsonLine\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    verbCount=0\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_=='VERB':\n",
    "            verbCount+=1\n",
    "        \n",
    "    return verbCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_count(jsonLine):\n",
    "    sentence=jsonLine\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    nounCount=0\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_=='NOUN' or token.pos=='PROPN':\n",
    "            nounCount+=1\n",
    "        \n",
    "    return nounCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_count(jsonLine):\n",
    "    sentence=jsonLine\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    adjCount=0\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_=='ADJ':\n",
    "            adjCount+=1\n",
    "        \n",
    "    return adjCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_length(jsonLine):\n",
    "    return len(jsonLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentimentFlex\n",
    "\n",
    "def get_sentiment_polarity(jsonLine):\n",
    "  \n",
    "    sentilex = sentimentFlex.sentiLexFlexToDict() # dict to use to know the sentiment\n",
    "    sentimentValue = sentimentFlex.polarity(sentilex,jsonLine)\n",
    "    \n",
    " \n",
    "    return sentimentValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_allcaps_to_word_ratio(jsonLine):\n",
    "  \n",
    "   \n",
    "    sentence=jsonLine.split()\n",
    "    matches = re.findall(\"([A-Z]+\\s?[A-Z]+[^a-z0-9\\W])\",jsonLine)\n",
    "\n",
    "    if(len(sentence)>0):\n",
    "        ratio= len(matches)/len(sentence)\n",
    "        return ratio\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_troll(user,message):\n",
    "    for troll in trolls:\n",
    "        retweet='RT @'+troll\n",
    "        if troll==user or message.startswith(retweet):\n",
    "            return False\n",
    "       \n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
